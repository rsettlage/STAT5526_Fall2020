<!DOCTYPE html>
<html class="no-js" lang="en-us">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Lecture 1D - Going Parallel (Pleasingly) - STAT-5526 Fall 2020</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<meta property="og:title" content="Lecture 1D - Going Parallel (Pleasingly)" />
<meta property="og:description" content="




Ok, the point to today’s discussion. Your project has exceeded what you can do locally. Possible reasons why:
" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://rsettlage.github.io/STAT5526_Fall2020/posts/lecture-1d/" />
<meta property="article:published_time" content="2020-11-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-11-05T00:00:00+00:00" />

	
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/STAT5526_Fall2020/css/style.css">
	
	<link rel="shortcut icon" href="/STAT5526_Fall2020/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/STAT5526_Fall2020/" title="STAT-5526 Fall 2020" rel="home">
				<div class="logo__title">STAT-5526 Fall 2020</div>
				<div class="logo__tagline">Official place to find HPC course material.</div>
			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/STAT5526_Fall2020/">Home</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/STAT5526_Fall2020/topics">Topics</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/STAT5526_Fall2020/posts">posts</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/STAT5526_Fall2020/homework">homework</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="https://github.com/rsettlage/STAT5526_Fall2020/tree/master/rmd">Rmd</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/STAT5526_Fall2020/homework-submit">Submitting homework</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/STAT5526_Fall2020/notes">notes</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/STAT5526_Fall2020/about/">About</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Lecture 1D - Going Parallel (Pleasingly)</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg>
	<time class="meta__text" datetime="2020-11-05T00:00:00">November 05, 2020</time>
</div>

<div class="meta__item-categories meta__item">
	<svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg>
	<span class="meta__text"><a class="meta__link" href="/STAT5526_Fall2020/categories/lecture1" rel="category">Lecture1</a></span>
</div>
</div>
		</header><div class="content post__content clearfix">
			<div id="reasons-why-your-compute-can-be-taking-too-long" class="section level3">
<h3>Reasons why your compute can be taking too long</h3>
<p>Ok, the point to today’s discussion. Your <em>project</em> has exceeded what you can do locally. Possible reasons why:</p>
<ol style="list-style-type: decimal">
<li>memory limits</li>
<li>storage limits</li>
<li>compute time is too long</li>
</ol>
<p>For most workstations, 16-48 GB of RAM and a few TB’s of local disk is about the practical limit. Most HPC clusters have nodes with much more RAM and networked parallel storage. For instance, on ARC machines, most nodes have 128-256 GB of RAM with a few having 3 TB. For storage, many HPC clusters have fast parallel storage. Within ARC, we have 7.5 PB on a parallel file system called BeeGFS.</p>
<hr />
</div>
<div id="compute-time-is-too-long" class="section level3">
<h3>Compute time is too long</h3>
<p>The last local compute issue, compute time is too long, is a more complicated discussion. We are going to focus on the last issue and talk about how you can scale your compute on an HPC cluster. Before you start, you should know what the cause of the slowness is. Is the process:</p>
<ul>
<li>i/o bound</li>
<li>memory bound</li>
<li>CPU bound</li>
</ul>
<p>Generally, this is a pretty advanced topic and involves performance tools etc to profile the application’s behavior. We are going to skip all that and think about the compute as a pipeline and classify it based on inputs/outputs and steps/calculations.</p>
<hr />
</div>
<div id="look-at-local-benchmarking" class="section level3">
<h3>Look at local benchmarking</h3>
<pre class="r"><code>comp_stats &lt;- read.delim(&quot;../img/user_data.tbl&quot;,sep=&quot;,&quot;)
comp_stats$size &lt;- as.numeric(comp_stats$size)
comp_stats &lt;- comp_stats[comp_stats$size&gt;0,]
ggplot(comp_stats,aes(x=as.factor(user),y=as.numeric(actual_solve))) +
  geom_violin() + facet_wrap(~size,scales=&quot;free&quot;)</code></pre>
<p><img src="/posts/Lecture_1d_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<p><img src="/posts/Lecture_1d_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<hr />
</div>
<div id="reasons-for-long-compute" class="section level3">
<h3>Reasons for long compute</h3>
<p>Here are some possible data flow/computing pipelines (plus some examples):</p>
<ol style="list-style-type: decimal">
<li>single data set, must all be computed on at one time, involves matrix operations
<ul>
<li>simple linear regression</li>
</ul></li>
<li>single data set, must all be computed on at one time, involves loops
<ul>
<li>bootstrapping</li>
<li>nonlinear regression using gradient descent</li>
<li>Monte Carlo methods</li>
</ul></li>
<li>single data set, must all be computed on at one time, involves many hyper parameters that must be optimized
<ul>
<li>Monte Carlo methods</li>
<li>gradient descent</li>
<li>machine learning algorithms</li>
</ul></li>
<li>single data set, can be processed in batches, must be aggregated at end
<ul>
<li>ML</li>
<li>batched gradient descent</li>
</ul></li>
<li>multiple data sets, identical processing on each
<ul>
<li>independent models using linear regression</li>
</ul></li>
</ol>
<p>And really any combination of the above. We will start first by talking through (3) and (5) together.</p>
<hr />
</div>
<div id="pleasingly-parallel-applications" class="section level3">
<h3>Pleasingly parallel applications</h3>
<p>Pleasingly parallel processing is exemplified by tasks that can be performed completely independently of each other.</p>
<ul>
<li><p>Suppose for instance, you have a slew of data sets, all independent, and want to create models for each. You could, given a lab with several workstations, start computing a model on each workstation independent of the others. On an HPC system, you would submit each data set + desired compute as a script to a scheduler. In our case Slurm. As compute nodes are available, the various data plus scripted model will be computed and results returned.</p></li>
<li><p>In a separate case, suppose you have a data set and have some sort of non-tunable parameter you want to test to create a model, for instance, perhaps a transformation of the response. Similar to the last, you could submit the data plus appropriate script for each desired transformation to Slurm. Slurm will, as before, assign compute resources as they are available and return results when those are available.</p></li>
</ul>
<p>As it turns out, the matrix mult code I sent you can be thought of this way. We were creating a data set of varying size and varying threads, repeated a few times, and timing both a crossprod and solve. With a slight refactor of the code, we could start a bunch of independent jobs and test the various parameters of interest.</p>
<p>Consider the code in solve_time.R. What if we were to run it like:</p>
<pre class="bash"><code>for i in {7..13}; do echo Rscript solve_time.R $i; done</code></pre>
<hr />
</div>
<div id="now-scale-out" class="section level3">
<h3>Now, scale out</h3>
<p>To span multiple nodes, use the scheduler!</p>
<pre class="bash"><code>
# run 50 replicates using 64 cores, matrix size = (2^13)^2
for i in {50}; do sbatch -c64 --export=NCOLS=13 SLRUM_solve_time.sh ; done

# what if we want to vary the parameters in a grid search
for cores in {4,8,12,16,32,64,128}; do 
    for ncols in {7..14}; do 
        for reps in {1..7}; do 
            sbatch -c$cores --export=NCOLS=$ncols SLRUM_solve_time.sh;
        done;
    done;
done
</code></pre>
<hr />
</div>
<div id="linux-version-of-the-matrix-ops" class="section level3">
<h3>Linux version of the matrix ops</h3>
<pre class="r"><code>linux_side &lt;- readRDS(&quot;../img/linux-128.RDS&quot;)
linux_side$size &lt;- as.numeric(linux_side$size)
linux_side &lt;- linux_side[linux_side$size&gt;0,]
linux_side %&gt;%
  ggplot(aes(x=as.factor(as.numeric(setthreads)),y=as.numeric(actual_solve))) +
    geom_violin() + 
    facet_wrap(~size,scales=&quot;free&quot;) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))</code></pre>
<p><img src="/posts/Lecture_1d_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="more-opportunities-for-parallelization" class="section level3">
<h3>More opportunities for parallelization</h3>
<p>We have been exploring MKL/OpenBLAS and OpenMP in the code so far. Within a node, MKL/OpenBLAS accelerate matrix math routines such as matrix multiplication, inverting, transposing, etc. The algorithms are way beyond what we need to know here. Where we will end is that many of these algorithms use threading to divide and conquer. The threading is often controlled by OpenMP. This is where we jump in.</p>
<hr />
</div>
<div id="openmp" class="section level3">
<h3>OpenMP</h3>
<p>OpenMP is basically a fork and join model of task launching within an application for shared memory systems (more on that below). What we did in the pleasingly parallel section can be thought of as a disjointed version of OpenMP. We started with a set of data and a script, we launched a bunch of tasks that completed independently, and now we would aggregate the results.</p>
<p>OpenMP does this within an application using threading. A typical use of OpenMP is parallelizing for loops. Think linear algebra! Unfortunately for us, OpenMP is for COMPILED languages. Are we out of luck? NO, but we have to use Rcpp or the like to use it, ie unless we have a package that wrote it in C/C++/Fortran or we do something in Rcpp, we won’t see it outside of the linear algebra routines.</p>
<hr />
</div>
<div id="openmp-example" class="section level3">
<h3>OpenMP example</h3>
<pre class="c"><code>## openMPCode example from Rcpp/examples/OpenMP/ by Dirk E.
openMPCode &lt;- &#39;
   // assign to C++ vector
   std::vector&lt;double&gt; x = Rcpp::as&lt;std::vector&lt; double &gt; &gt;(xs);
   size_t n = x.size();
#pragma omp parallel for shared(x, n)
   for (size_t i=0; i&lt;n; i++) {
       x[i] = ::log(x[i]);
   }
   return Rcpp::wrap(x);
&#39;</code></pre>
</div>
<div id="step-back-and-look-at-our-processor" class="section level3">
<h3>Step back and look at our processor</h3>
<p>In today’s world, we are getting speedups by having multiple “mini” processors, called cores, bundled together as a single processor.</p>
<p>TinkerCliffs:
+ 1 node has 2 processors
+ 1 processor has 64 cores</p>
<p><img src="../img/Processors.png" alt="Processor" />
### TinkerCliffs</p>
<p>A single AMD ROME processor has 8 CCD’s, each with 8 cores bundled together to create the full processor.</p>
<div class="figure">
<img src="../img/ROME2.png" alt="" />
<p class="caption">Rome2</p>
</div>
</div>
<div id="rome1" class="section level2">
<h2><img src="../img/ROME1.png" alt="Rome1" /></h2>
<div id="machine-differences" class="section level3">
<h3>Machine differences</h3>
<p>OK, what is the point to all this??</p>
<ol style="list-style-type: decimal">
<li>Node make, model, proc choice matters<br />
</li>
<li>Some knowledge of what your script is doing can point to a solution</li>
</ol>
<p><img src="/posts/Lecture_1d_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<hr />
</div>
<div id="pleasingly-parallel-vs-coupled" class="section level3">
<h3>Pleasingly parallel vs coupled</h3>
<p>Above, we were giving examples of a single data, ie simulated matrix elements, but varying a hyperparameter to show differences in computing speeds. What if we are coupled?</p>
<p>Couple systems means not independent. Examples:</p>
<ul>
<li>iterative updates<br />
</li>
<li>Monte Carlo random walks</li>
</ul>
<p>In these cases, there may be opportunities for partial parallelization of the algorithm, but perhaps not the whole thing. Often, this means we are stuck to a single node. What can we do within a single node?</p>
<pre class="r"><code># summary statistics of sample
n    &lt;- 30
ybar &lt;- 15
s2   &lt;- 3

# sample from the joint posterior (mu, tau | data)
mu     &lt;- rep(NA, 11000)
tau    &lt;- rep(NA, 11000)
T      &lt;- 1000    # burnin
tau[1] &lt;- 1  # initialisation
for(i in 2:11000) {   
    mu[i]  &lt;- rnorm(n = 1, mean = ybar, sd = sqrt(1 / (n * tau[i - 1])))    
    tau[i] &lt;- rgamma(n = 1, shape = n / 2, scale = 2 / ((n - 1) * s2 + n * (mu[i] - ybar)^2))
}
mu  &lt;- mu[-(1:T)]   # remove burnin
tau &lt;- tau[-(1:T)] # remove burnin
hist(mu)</code></pre>
<hr />
</div>
<div id="other-opportunities-for-parallization" class="section level3">
<h3>Other opportunities for parallization</h3>
<ul>
<li>parallel/foreach package</li>
<li>Rmpi</li>
<li>pbdr*</li>
</ul>
<p>Within a node, if there are loops or other independent tasks, you can use the parallel or foreach packages to start “workers”. These workers can then perform a task. Generally, the task is similar, but they do not have to be.</p>
<p>If you must span nodes, but the process is not completely decoupled, you need to think about memory and data location. Rmpi allows passing of messages back and forth (using MPI) between workers on different nodes (more precisely, in non-shared memory spaces) to allow updating of status.</p>
<p>Finally, the pbdr* suite of packages, allows a combination of the above and includes matrix libraries that can span nodes.</p>
</div>
</div>

		</div>
		
<div class="post__tags tags clearfix">
	<svg class="tags__icon icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/STAT5526_Fall2020/tags/parallelizing/" rel="tag">Parallelizing</a></li>
	</ul>
</div>
	</article>
</main>




			</div>
			<aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH..." value="" name="q" aria-label="SEARCH...">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="http://rsettlage.github.io/STAT5526_Fall2020/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/STAT5526_Fall2020/posts/lecture-1a/">Lecture 1A - HPC Cluster Organization</a></li>
			<li class="widget__item"><a class="widget__link" href="/STAT5526_Fall2020/posts/lecture-1b/">Lecture 1B - Scheduler/Software/Storage</a></li>
			<li class="widget__item"><a class="widget__link" href="/STAT5526_Fall2020/posts/lecture-1c/">Lecture 1C - Containers and R</a></li>
		</ul>
	</div>
</div>
<div class="widget-categories widget">
	<h4 class="widget__title">Categories</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/STAT5526_Fall2020/categories/course-logistics">Course logistics</a></li>
			<li class="widget__item"><a class="widget__link" href="/STAT5526_Fall2020/categories/homework">Homework</a></li>
			<li class="widget__item"><a class="widget__link" href="/STAT5526_Fall2020/categories/lecture1">Lecture1</a></li>
			<li class="widget__item"><a class="widget__link" href="/STAT5526_Fall2020/categories/lecture2">Lecture2</a></li>
		</ul>
	</div>
</div>
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/containers" title="Containers">Containers</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/git" title="Git">Git</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/gp" title="Gp">Gp</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/homework" title="Homework">Homework</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/hpc" title="Hpc">Hpc</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/keras" title="Keras">Keras</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/monte-carlo" title="Monte carlo">Monte carlo</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/neural-networks" title="Neural networks">Neural networks</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/parallelizing" title="Parallelizing">Parallelizing</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/r" title="R">R</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/r-setup" title="R setup">R setup</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/scheduler" title="Scheduler">Scheduler</a>
		<a class="widget-taglist__link widget__link btn" href="/STAT5526_Fall2020/tags/topics" title="Topics">Topics</a>
	</div>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2020 STAT-5526 Fall 2020.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
			<script type="text/javascript"
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
      </script>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/STAT5526_Fall2020/js/menu.js"></script></body>
</html>