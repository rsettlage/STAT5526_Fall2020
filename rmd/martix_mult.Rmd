---
title: "matrix_mult.Rmd"
author: "Robert Settlage"
date: "11/5/2020"
output: pdf_document
---

This is just a benchmarking script for fun.  IF you have trouble with memory, try to set: `R_MAX_VSIZE=100Gb`.  You can read up on it here: <https://r.789695.n4.nabble.com/R-3-5-0-vector-memory-exhausted-error-on-readBin-td4750237.html>.  If that is a bit much, just reduce the max matrix size (`max_rows`) from 12 by 2 until the code runs.


Load our libraries.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=TRUE, include=TRUE)
if(!require(RhpcBLASctl)){
    install.packages("RhpcBLASctl")
}
if(!require(knitr)){
    install.packages("knitr")
}
if(!require(ggplot2)){
    install.packages("ggplot2")
}
if(!require(dplyr)){
    install.packages("dplyr")
}
library(ggplot2);library(knitr);
library(dplyr);library(RhpcBLASctl) ## will throw an error if the install failed
```

## Do the compute

Basically, pull some stats from the local machine, run though some matrix ops, collect some timings and save.  The stats we are after are:

1. tcrossprod - combination of transpose and matrix mult
2. solve - straight up
3. pull the max deviation from 0 (solve is implemented as an optimization, so not perfect)

```{r getstats, echo=FALSE}
#get a couple of system specs for later
cpus<-get_num_cores()
threads <- get_num_procs()
systemname <- Sys.info()[1]
username <- Sys.info()[7]

# quick function to create a matrix, transpose it, square it, 
# solve it, and get max deviation
matrix_fun <- function(size=6){
  set.seed(34534) ## don't want a random number difference
  n <- 2^size
  M <- matrix(rnorm(n^2),nrow=n)
  # going to use system.time instead of microbenchmark to get each run
  # the reason is that I want to abort if it is taking too long, otherwise, microbenchmark rocks!
  tc_time <- system.time(MtM <- tcrossprod(M))[3]
  s_time <- system.time(s <- solve(MtM))[3]
  maxdiff <- max(abs(s%*%MtM-diag(n)))
  return(c(n,tc_time,s_time,maxdiff))
}

reps <- 9; max_rows <- 12
max_results <- matrix(0,nrow = reps*max_rows*threads,ncol = 7) #result container
iter <- 0 # keep track of which this is
for(i in 1:threads){
  ## need to set the threads, but don't know which one to set, so set them all
  blas_set_num_threads(i)
  omp_set_num_threads(i)
  Sys.setenv(VECLIB_MAXIMUM_THREADS=i)
  for(j in 7:max_rows){ 
    for(k in 1:reps){ ### just repeating it a few times to get some idea of variability
      iter <- iter + 1
      max_results[iter,] <- c(cpus,threads,i,matrix_fun(size=j))
      if(k==1){
        cat("for matrix of size",(2^j)^2,"elements using",i,"threads, takes",
            max_results[iter,5],"secs","\n",sep=" ")
      }
      if(max_results[iter,5]>200){
        break
      }
    }
  }
}

full_output <- data.frame(cbind(systemname,username,max_results))
colnames(full_output)<-c("system","user","cores","threads","setthreads","size","actual_mult","actual_solve","maxDiff")
saveRDS(full_output,paste0(username,".RDS"))

```

## Make some pretty output

I am biased to violin plots over boxplots because I like to see some semblance of density.  When I do boxplots, I always add the points using beeswarm, but here, boxplots.  We will just plot elements by time and maybe facet on threads.  We could make this prettier, but good enough.

```{r plots, echo=FALSE}
full_output %>%
  filter(size>0) %>%
  ggplot(aes(x=as.factor(as.numeric(setthreads)),y=as.numeric(actual_solve))) + 
  geom_violin() + facet_wrap(~as.numeric(size), scales="free_y")
```

## Appendix - Relevant Code

```{r Appendix, ref.label=c("getstats"), echo=TRUE, eval=FALSE, tidy=FALSE, include=TRUE}
  
```